{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21db6e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "GITHUB_TOKEN = 'token no here...'\n",
    "headers = {\"Authorization\": f\"token {GITHUB_TOKEN}\"}\n",
    "\n",
    "def fetch_users():\n",
    "    users = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        url = f\"https://api.github.com/search/users?q=location:seattle+followers:>200&page={page}\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "        data = response.json()\n",
    "\n",
    "        if 'items' not in data:\n",
    "            break\n",
    "\n",
    "        users.extend(data['items'])\n",
    "        if len(data['items']) == 0:\n",
    "            break\n",
    "        page += 1\n",
    "\n",
    "    return users\n",
    "\n",
    "\n",
    "def get_detailed_user_info(users):\n",
    "    user_data = []\n",
    "    for user in users:\n",
    "        user_response = requests.get(f\"https://api.github.com/users/{user['login']}\", headers=headers)\n",
    "        user_info = user_response.json()\n",
    "        company = user_info.get('company', '').strip().lstrip('@').upper() if user_info.get('company') else None\n",
    "        user_data.append({\n",
    "            'login': user_info['login'],\n",
    "            'name': user_info.get('name'),\n",
    "            'company': company,\n",
    "            'location': user_info.get('location'),\n",
    "            'email': user_info.get('email'),\n",
    "            'hireable': user_info.get('hireable', False),\n",
    "            'bio': user_info.get('bio'),\n",
    "            'public_repos': user_info.get('public_repos'),\n",
    "            'followers': user_info.get('followers'),\n",
    "            'following': user_info.get('following'),\n",
    "            'created_at': user_info.get('created_at')\n",
    "        })\n",
    "    return user_data\n",
    "\n",
    "\n",
    "def save_users_to_csv(user_data):\n",
    "    users_df = pd.DataFrame(user_data)\n",
    "    users_df.to_csv('users.csv', index=False)\n",
    "\n",
    "users = fetch_users()\n",
    "user_data = get_detailed_user_info(users)\n",
    "save_users_to_csv(user_data)\n",
    "\n",
    "\n",
    "def fetch_repos_for_user(user_login):\n",
    "    repo_data = []\n",
    "    url = f\"https://api.github.com/users/{user_login}/repos?per_page=100\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    repos = response.json()\n",
    "    for repo in repos:\n",
    "        repo_data.append({\n",
    "            'login': user_login,\n",
    "            'full_name': repo['full_name'],\n",
    "            'created_at': repo['created_at'],\n",
    "            'stargazers_count': repo['stargazers_count'],\n",
    "            'watchers_count': repo['watchers_count'],\n",
    "            'language': repo['language'],\n",
    "            'has_projects': repo['has_projects'],\n",
    "            'has_wiki': repo['has_wiki'],\n",
    "            'license_name': repo['license']['name'] if repo['license'] else None\n",
    "        })\n",
    "    return repo_data\n",
    "\n",
    "\n",
    "\n",
    "def fetch_all_repositories():\n",
    "    users_df = pd.read_csv('users.csv')\n",
    "    all_repos = []\n",
    "    for login in users_df['login']:\n",
    "        all_repos.extend(fetch_repos_for_user(login))\n",
    "    return all_repos\n",
    "\n",
    "repos = fetch_all_repositories()\n",
    "repos_df = pd.DataFrame(repos)\n",
    "repos_df.to_csv('repositories.csv', index=False)\n",
    "\n",
    "\n",
    "users_df = pd.read_csv('users.csv')\n",
    "repos_df = pd.read_csv('repositories.csv')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "users_df['hireable'] = users_df['hireable'].fillna(False).astype(bool)\n",
    "\n",
    "#1\n",
    "top_5_users = users_df.nlargest(5, 'followers')['login'].tolist()\n",
    "print(','.join(top_5_users))\n",
    "\n",
    "#2\n",
    "users['created_at'] = pd.to_datetime(users['created_at'])\n",
    "top_earliest = users.sort_values(by='created_at').head()\n",
    "print(','.join(top_earliest['login'].tolist()))\n",
    "\n",
    "\n",
    "#3\n",
    "repos['license_name'].value_counts().head(4)\n",
    "\n",
    "\n",
    "#4\n",
    "users['company'].value_counts().head(1)\n",
    "\n",
    "\n",
    "\n",
    "#5\n",
    "repos['language'].value_counts().head(1)\n",
    "\n",
    "#6\n",
    "repos_2020 = repos[repos['login'].isin(users_after_2020['login'].tolist())]\n",
    "repos_2020['language'].value_counts().head()\n",
    "\n",
    "#7\n",
    "avg_stars = repos.groupby('language')['stargazers_count'].mean()\n",
    "top_lang = avg_stars.idxmax()\n",
    "top_stars = avg_stars.max()\n",
    "print(top_lang, top_stars)\n",
    "\n",
    "#8\n",
    "users['leader_strength'] = users['followers'] / (1 + users['following'])\n",
    "top5_lead = users.sort_values(by='leader_strength', ascending=False).head()\n",
    "print(','.join(top5_lead['login'].tolist()))\n",
    "\n",
    "#9\n",
    "correlation =users['followers'].corr(users['public_repos'])\n",
    "correlation\n",
    "\n",
    "\n",
    "#10\n",
    "import csv\n",
    "followers = []\n",
    "public_repos = []\n",
    "with open('users.csv', 'r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        followers_count = int(row['followers'])\n",
    "        public_repos_count = int(row['public_repos'])\n",
    "        followers.append(followers_count)\n",
    "        public_repos.append(public_repos_count)\n",
    "if len(followers) > 1 and len(public_repos) > 1:\n",
    "    slope, intercept = np.polyfit(public_repos, followers, 1)\n",
    "    \n",
    "    print(f\"{slope:.3f}\")\n",
    "else:\n",
    "    print(\"Error\")\n",
    "\n",
    "\n",
    "#11\n",
    "repos_df['has_projects'] = repos_df['has_projects'].astype(int)\n",
    "repos_df['has_wiki'] = repos_df['has_wiki'].astype(int)\n",
    "correlation = repos_df['has_projects'].corr(repos_df['has_wiki'])\n",
    "print(f\"Correlation between projects and wiki enabled: {correlation:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "#12\n",
    "users_df = pd.read_csv('users.csv')\n",
    "hireable_avg_following = users_df[users_df['hireable'] == True]['following'].mean()\n",
    "non_hireable_avg_following = users_df[users_df['hireable'] == False]['following'].mean()\n",
    "difference = hireable_avg_following - non_hireable_avg_following\n",
    "print(f\"Difference in following count: {difference:.3f}\")\n",
    "\n",
    "#13\n",
    "users_df = users_df.dropna(subset=['bio'])\n",
    "users_df['bio_length'] = users_df['bio'].apply(len)\n",
    "bio_followers_correlation = users_df['bio_length'].corr(users_df['followers'])\n",
    "print(f\"Correlation of bio length with followers: {bio_followers_correlation:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "#14\n",
    "repos_df['created_at'] = pd.to_datetime(repos_df['created_at'])\n",
    "weekend_repos = repos_df[repos_df['created_at'].dt.weekday >= 5]\n",
    "weekend_repo_counts = weekend_repos['login'].value_counts().head(5)\n",
    "print(\"Top users by weekend-created repos:\", \", \".join(weekend_repo_counts.index))\n",
    "\n",
    "\n",
    "\n",
    "#15\n",
    "fraction_hierable = users[users['hireable'] == True]['email'].notna().mean()\n",
    "fraction_non_hierable = users[users['hireable'] == False]['email'].notna().mean()\n",
    "diff = fraction_hierable - fraction_non_hierable\n",
    "\n",
    "\n",
    "#16\n",
    "new_users = users[users['name'].notna()].copy()\n",
    "new_users['surname'] = new_users['name'].str.split().str[-1].str.strip()\n",
    "surname_counts = new_users['surname'].value_counts()\n",
    "max_count = surname_counts.max()\n",
    "common_surnames = surname_counts[surname_counts == max_count].index.tolist()\n",
    "common_surnames.sort()\n",
    "print(','.join(common_surnames))\n",
    "\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "files.download('users.csv')\n",
    "\n",
    "files.download('repositories.csv')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
